import onnx
import onnxoptimizer
import onnxruntime as ort
import numpy as np
import subprocess

# ========== Step 1: ä½¿ç”¨ onnx-simplifier ç®€åŒ–æ¨¡åž‹ ==========
def simplify_onnx(input_model, simplified_model):
    print(">>> Simplifying ONNX model...")
    subprocess.run(["python3", "-m", "onnxsim", input_model, simplified_model], check=True)
    



# ========== Step 1.5: ä¿®å¤ initializer å¼•ç”¨ ==========
def fix_initializers(model: onnx.ModelProto) -> onnx.ModelProto:
    """
    å°†æ‰€æœ‰ initializer ç¡®ä¿åŠ å…¥ graph.input
    é¿å… onnxoptimizer æŠ¥ Unresolved value references
    """
    input_names = [i.name for i in model.graph.input]
    for init in model.graph.initializer:
        if init.name not in input_names:
            # ä½¿ç”¨ initializer çš„ shape å’Œ type åˆ›å»º TensorValueInfo
            vi = onnx.helper.make_tensor_value_info(
                init.name,
                init.data_type,
                list(init.dims)
            )
            model.graph.input.append(vi)
    return model
    
'''

['adjust_add', 'rename_input_output', 'set_unique_name_for_nodes', 'nop', 'eliminate_nop_cast', 'eliminate_nop_dropout',
'eliminate_nop_flatten', 'extract_constant_to_initializer', 'eliminate_if_with_const_cond', 'eliminate_nop_monotone_argmax', 
'eliminate_nop_pad', 'eliminate_nop_concat', 'eliminate_nop_split', 'eliminate_nop_expand', 'eliminate_shape_gather', 
'eliminate_slice_after_shape', 'eliminate_nop_transpose', 'fuse_add_bias_into_conv', 'fuse_bn_into_conv', 'fuse_consecutive_concats', 

'fuse_consecutive_log_softmax', 'fuse_consecutive_reduce_unsqueeze', 'fuse_consecutive_squeezes', 'fuse_consecutive_transposes', 
'fuse_matmul_add_bias_into_gemm', 'fuse_pad_into_conv', 'fuse_pad_into_pool', 'fuse_transpose_into_gemm', 'replace_einsum_with_matmul', 
'lift_lexical_references', 'split_init', 'split_predict', 'fuse_concat_into_reshape', 'eliminate_nop_reshape', 'eliminate_nop_with_unit', 
'eliminate_common_subexpression', 'fuse_qkv', 'fuse_consecutive_unsqueezes', 'eliminate_deadend', 'eliminate_identity', 'eliminate_shape_op', 
'fuse_consecutive_slices', 'eliminate_unused_initializer', 'eliminate_duplicate_initializer', 'adjust_slice_and_matmul', 'rewrite_input_dtype']



'''


'''
import onnx
from onnx import helper, TensorProto

# Pad -> MaxPool
pad = helper.make_node(
    "Pad", 
    inputs=["input"], outputs=["pad_out"],
    mode="constant",
    pads=[0, 0, 1, 1, 0, 0, 1, 1],  # only pad H/W
    value=0.0
)

pool = helper.make_node(
    "MaxPool",
    inputs=["pad_out"], outputs=["pool_out"],
    kernel_shape=[3, 3],
    strides=[1, 1],
    pads=[0, 0, 0, 0]
)


âœ… 1. split_init â€”â€” æ‹†å‡ºé™æ€éƒ¨åˆ†

æ­£å¦‚ä½ å‰é¢ç†è§£çš„ï¼š

è¯†åˆ«æ‰€æœ‰ä¸Žè¾“å…¥æ— å…³çš„èŠ‚ç‚¹ï¼›

æ‹†æˆ Init Graphï¼›

Predict Graph ç”¨ Init è¾“å‡ºæ›¿ä»£è¿™äº›èŠ‚ç‚¹ã€‚

è¾“å‡ºç»“æžœï¼š

InitGraph.onnx

PredictGraph.onnxï¼ˆä½†æ­¤æ—¶è¿˜åŒ…å«ä¸€äº›æœªä¼˜åŒ–çš„å¸¸é‡è®¡ç®—ï¼‰

âœ… 2. constant_folding â€”â€” å¸¸é‡æŠ˜å 

è¿™æ˜¯æŽ¥ä¸‹æ¥éžå¸¸å…³é”®çš„ä¸€æ­¥ã€‚

æŠŠæ‰€æœ‰å¯ä»¥åœ¨ç¼–è¯‘æ—¶è®¡ç®—å‡ºæ¥çš„èŠ‚ç‚¹ï¼Œæå‰è®¡ç®—æˆ Constantã€‚

ä¾‹å¦‚ï¼š
Add(Constant(2), Constant(3)) â†’ Constant(5)
æˆ–ï¼š
MatMul(Constant(W), Constant(X)) â†’ Constant(Y)
åœ¨ split_init ä¹‹åŽï¼ŒInit Graph ä¸­å¾€å¾€æœ‰å¤§é‡å¸¸é‡æµåŠ¨è·¯å¾„ï¼š

æƒé‡å¸¸é‡

shape è®¡ç®—

BN å‚æ•°èžåˆ

precompute ä½ç½®ç¼–ç 

ç»è¿‡ constant foldingï¼Œè¿™äº›èŠ‚ç‚¹å°±ä¼šè¢«ç›´æŽ¥è®¡ç®—å¹¶æ›¿æ¢ä¸ºå¸¸é‡æ•°æ®ã€‚
â†’ å‡å°‘è¿è¡Œæ—¶è®¡ç®—å¼€é”€ã€‚

âœ… 3. eliminate_deadend â€”â€” åˆ é™¤æ­»èŠ‚ç‚¹ï¼ˆæ— ç”¨å­å›¾ï¼‰

æ‹†åˆ†å’Œå¸¸é‡æŠ˜å ä¹‹åŽï¼Œå¾€å¾€ä¼šé—ç•™ä¸€äº›ï¼š

æœªè¢«ä½¿ç”¨çš„èŠ‚ç‚¹ï¼›

æ–­å¼€çš„å­å›¾ï¼›

ä¸´æ—¶å¼ é‡ã€‚

è¿™ä¸ª Pass è´Ÿè´£ï¼š

ä»Žè¾“å‡ºç«¯å‘ä¸Šè¿½æº¯ä¾èµ–ï¼›

åˆ é™¤æ‰€æœ‰ä¸å†è¢«å¼•ç”¨çš„èŠ‚ç‚¹ï¼›

æ¸…ç†æŽ‰å­¤ç«‹çš„è®¡ç®—æ”¯è·¯ã€‚

ðŸ’¡ ç±»ä¼¼äºŽç¼–è¯‘å™¨é‡Œçš„ã€ŒDead Code Eliminationã€ã€‚

âœ… 4. split_predict â€”â€” ä¿ç•™æŽ¨ç†ä¸»å›¾

åˆ°è¿™é‡Œå†è¿è¡Œ split_predictï¼Œåšä¸¤ä»¶äº‹ï¼š

ä¿ç•™ä¸»æŽ¨ç†å›¾ï¼ˆPredict Graphï¼‰ï¼›

ç§»é™¤æ‰€æœ‰ Init-only è®¡ç®—å’Œä¸­é—´ç¼“å­˜ï¼›

æ›´æ–°è¾“å…¥ç­¾åï¼Œä½¿ Predict Graph ä»…ä¾èµ–ï¼š

åŽŸå§‹æ¨¡åž‹è¾“å…¥ï¼›

Init Graph è¾“å‡ºï¼ˆä½œä¸ºå¤–éƒ¨å¸¸é‡ï¼‰ã€‚

æœ€ç»ˆå½¢æˆç‹¬ç«‹å¯æ‰§è¡Œçš„ â€œè½»é‡æŽ¨ç†å›¾â€ã€‚

âœ… 5. ï¼ˆå¯é€‰ï¼‰graph_cleanup â€”â€” æ¸…ç†å›¾ç»“æž„

åœ¨æ‹†åˆ†å’Œåˆ é™¤æ“ä½œä¹‹åŽï¼Œæœ‰æ—¶å›¾ä¸­è¿˜ä¼šé—ç•™ï¼š

æ— ç”¨ initializerï¼›

é‡å¤ nameï¼›

ç©º shapeï¼›

ä¸å¿…è¦çš„ Cast/Identityã€‚

graph_cleanup ä¼šç»Ÿä¸€æ¸…ç†è¿™äº›é—®é¢˜ï¼Œä¿è¯æ¨¡åž‹ç»“æž„åˆæ³•ã€‚


'''

# ========== Step 2: ä½¿ç”¨ onnxoptimizer è¿›ä¸€æ­¥å›¾ä¼˜åŒ– ==========
def optimize_onnx(input_model, optimized_model):
    print(">>> Optimizing ONNX model with onnxoptimizer...")
    
    passes = onnxoptimizer.get_available_passes()
    print(onnxoptimizer.get_available_passes())

    model = onnx.load(input_model)
    model = fix_initializers(model)  # ä¿®å¤ initializer å¼•ç”¨

    # æ‰“å°ä¼˜åŒ–å‰çš„ç®—å­ç»Ÿè®¡
    original_nodes = len(model.graph.node)
    original_ops = [node.op_type for node in model.graph.node]
    print(f"ä¼˜åŒ–å‰: {original_nodes} ä¸ªç®—å­")
    print(f"ç®—å­åˆ†å¸ƒ: { {op: original_ops.count(op) for op in set(original_ops)} }")

    # å¯é€‰ä¼˜åŒ– passï¼ˆæ ¹æ®éœ€æ±‚å¢žå‡ï¼‰
    # passes = [
    #     "eliminate_identity",             # åˆ é™¤ Identity èŠ‚ç‚¹
    #     "eliminate_nop_transpose",        # åˆ é™¤æ— æ•ˆçš„ Transpose
    #     "eliminate_nop_pad",              # åˆ é™¤æ— æ•ˆçš„ Pad
    #     "eliminate_deadend",              # åˆ é™¤æ­»èŠ‚ç‚¹
    #     "fuse_consecutive_transposes",    # èžåˆè¿žç»­çš„ Transpose
    #     "fuse_bn_into_conv",              # èžåˆ BN åˆ° Conv
    # ]
    
    
    print(len(passes))
    exclude_passes = [
        "split_init",
        "rewrite_input_dtype", 
        "adjust_add", 
        "adjust_slice_and_matmul",
        "eliminate_nop_cast"
]

    
    
    passes = [e for e in passes if e not in exclude_passes]
    print(len(passes))

    optimized_model_proto = onnxoptimizer.optimize(model, passes)

    # æ‰“å°ä¼˜åŒ–åŽçš„ç®—å­ç»Ÿè®¡
    optimized_nodes = len(optimized_model_proto.graph.node)
    optimized_ops = [node.op_type for node in optimized_model_proto.graph.node]
    print(f"ä¼˜åŒ–åŽ: {optimized_nodes} ä¸ªç®—å­")
    print(f"ç®—å­åˆ†å¸ƒ: { {op: optimized_ops.count(op) for op in set(optimized_ops)} }")

    # ä¿å­˜ä¼˜åŒ–åŽçš„æ¨¡åž‹
    onnx.save(optimized_model_proto, optimized_model)

# ========== Step 3: ä½¿ç”¨ ONNX Runtime è¿›è¡ŒæŽ¨ç†æµ‹è¯• ==========
def run_inference(model_path):
    print(">>> Running inference with ONNX Runtime...")
    sess_options = ort.SessionOptions()
    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_EXTENDED

    session = ort.InferenceSession(model_path, sess_options)

    # èŽ·å–è¾“å…¥ä¿¡æ¯
    input_name = session.get_inputs()[0].name
    input_shape = session.get_inputs()[0].shape
    input_type = session.get_inputs()[0].type
    print(f"Input name: {input_name}, shape: {input_shape}, type: {input_type}")

    # æž„é€ ä¸€ä¸ªéšæœºè¾“å…¥ï¼ˆä»…ç”¨äºŽæµ‹è¯•ï¼‰
    dummy_input = np.random.randn(*[dim if isinstance(dim, int) else 1 for dim in input_shape]).astype(np.float32)

    outputs = session.run(None, {input_name: dummy_input})
    print(f"Output shape: {outputs[0].shape}")

# ========== Main ==========
if __name__ == "__main__":
    original_model = "./output/onnx/lightstereo_s_sceneflow_general_opt_256_512_sim_conv.onnx"
    # original_model = "./output/model_480x640.onnx"
    simplified_model = "./output/onnx/model_simplified.onnx"
    optimized_model = "./output/onnx/model_optimized.onnx"

    simplify_onnx(original_model, simplified_model)
    optimize_onnx(simplified_model, optimized_model)
    # run_inference(optimized_model)

    print(">>> All steps done!")